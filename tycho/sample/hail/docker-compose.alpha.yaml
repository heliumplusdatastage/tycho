version: '3.0'

##################################################################################################
#
# This application creates a Hail workspace.
#   Hail provides scalable genomic data tools.
#   It is a library for the Apache Spark analytics cluster system.
#   The workspace also provides JupyterLab as a front end to the system.
#
# The workspace can be configured at launch as follows:
#   cluster_worker_replicas: The number of Spark worker jobs to run.
#        Apache Spark uses a master/worker architecture where multiple workers
#        execute analytic tasks.
#   cluster_worker_cores: The number of cores to request from the underlying
#        execution container orchestration platform. In general, this supports
#        fractional CPU allocations. This is the maximum CPU allocation the
#        worker containers will have access to.
#   cluster_worker_memory: The total amount of host memory to expose to worker
#        containers. Can be specified in GB or MB: 1GB, 512M, etc.
#   spark_worker_cores: Number of cores the Spark worker process should request.
#        This number must be an integer. Whatever CPU allocation is requested from the platform,
#        these will be presented to the container as CPUs. Spark requires integer core counts.
#   spark_worker_memory: The amount of memory for the Spark worker process in the container
#        to request.
#
services:

  # A non-root container for JupyterLab.
  #   A multi-stage Docker build takes Java and Python from bitnami java and python containers.
  #   A version of Spark compatible with Hail is installed.
  #   It instegrates Hail into Spark and Spark into Jupyter.
  jupyter:
    image: heliumdatastage/jupyter-hail:latest
    ports:
      - '${jupyter_port}:8000'

  # This is the bitnami spark container, a minimalist, non-root image with
  # good configuration options.
  spark:
    image: heliumdatastage/spark
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=0.0.0.0
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '${spark_master_ui_port}:8080'
      - '${spark_master_port}:7077'

  # The worker process uses the same image as the master and can be scaled up or down.
  # Number of instances is controlled by the cluster_worker_replicas environment setting.
  # Each replica must be able to connect to the master.
  # The ${app_id} is a GUID defined by the app launching infrastructure for this instance.
  # The hostname of other  containers in this app is given by <hostname>-${app_id}
  # Since the master is called spark and listens for Spark connections on port 7077, the worker connects to it as
  # spark://spark-${app_id}:${spark_master_port}
  #
  # This container also uses docker-compose v3.0 metadat for specifying deployment characteristics.
  # These include replicas, CPU and memory requirements, etc.
  spark-worker:
    image: heliumdatastage/spark
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-${app_id}:${spark_master_port}
      - SPARK_WORKER_MEMORY=${spark_worker_memory}
      - SPARK_WORKER_CORES=${spark_worker_cores}
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    deploy:
      mode: replicated
      replicas: ${cluster_worker_replicas}
      resources:
        limits:
          cpus: '${cluster_worker_cores}'
          memory: ${cluster_worker_memory}
        reservations:
          cpus: '${cluster_worker_cores}'
          memory: ${cluster_worker_memory}
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 5
        window: 60s



